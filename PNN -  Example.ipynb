{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Neural Network : Classification\n",
    "[Iqbal Basyar](https://github.com/underground-11), 2018\n",
    "\n",
    "*Notebook ini digunakan untuk referensi tugas 1.3 Machine Learning : PNN* <br>\n",
    "Deksripsi tugas : [link](https://github.com/underground-11/Semester_6/blob/master/Asdos%20Machine%20Learning/Tugas%203%20Machine%20Learning/Tugas1.3.pdf) <br>\n",
    "Data Train :  [link](https://github.com/underground-11/Semester_6/blob/master/Asdos%20Machine%20Learning/Tugas%203%20Machine%20Learning/data_train_PNN.txt) <br>\n",
    "Data Test (no label): [link](https://github.com/underground-11/Semester_6/blob/master/Asdos%20Machine%20Learning/Tugas%203%20Machine%20Learning/data_test_PNN.txt) <br>\n",
    "\n",
    "*Catatan : Install Plotly di mesin anda untuk menggunakan plot dalam notebook ini*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Library Needs\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as la\n",
    "import plotly.plotly as ply\n",
    "from plotly.offline import *\n",
    "from plotly.graph_objs import *\n",
    "from plotly import __version__\n",
    "# print ('Plotly Version : ',__version__) # requires version >= 1.9.0\n",
    "init_notebook_mode(connected=True) # Set this to True if you want to use plotly Offline\n",
    "\n",
    "#You can change this credential below if you have pltoly account\n",
    "plotly.tools.set_credentials_file(username='Underground-11', api_key='jCY5gx5Il7KMN2I03FeH') #My account's credential. Don't worry, it's for public use\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataTrain = pd.read_csv('data_train_PNN.txt', delimiter = \"\\t\").round(9)\n",
    "dataTest = pd.read_csv('data_test_PNN.txt', delimiter = \"\\t\").round(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the data to make it easier to plot (You don't have to to this. But it helps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class0 = dataTrain.loc[dataTrain['label'] == 0].reset_index(drop = True)\n",
    "class1 = dataTrain.loc[dataTrain['label'] == 1].reset_index(drop = True)\n",
    "class2 = dataTrain.loc[dataTrain['label'] == 2].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot Data Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~underground-11/1.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trace1 = go.Scatter3d(\n",
    "    name = 'Class 0',\n",
    "    x=class0['att1'],\n",
    "    y=class0['att2'],\n",
    "    z=class0['att3'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        line=dict(\n",
    "            color='rgba(217, 217, 0, 0.14)',\n",
    "            width=0.2\n",
    "        ),\n",
    "        opacity=0.9\n",
    "    )\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter3d(\n",
    "    name = 'Class 1',\n",
    "    x=class1['att1'],\n",
    "    y=class1['att2'],\n",
    "    z=class1['att3'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        line=dict(\n",
    "            color='rgba(217, 217, 217, 0.14)',\n",
    "            width=0.2\n",
    "        ),\n",
    "        opacity=0.9\n",
    "    )\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter3d(\n",
    "    name = 'Class 2',\n",
    "    x=class2['att1'],\n",
    "    y=class2['att2'],\n",
    "    z=class2['att3'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        line=dict(\n",
    "            color='rgba(217, 217, 217, 0.14)',\n",
    "            width=0.2\n",
    "        ),\n",
    "        opacity=0.9\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "this_layout = go.Layout(\n",
    "    title = 'Data Train',\n",
    "#     height = '800' ,\n",
    "    scene = dict(\n",
    "        xaxis = dict(\n",
    "            title='Att 1'),\n",
    "        yaxis = dict(\n",
    "            title='Att 2'),\n",
    "        zaxis = dict(\n",
    "            title='Att 3'),),\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=25\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=this_layout)\n",
    "ply.iplot(fig, filename='Data Train Scatter') #it took some times depend on your internet connection to Plotly\n",
    "# iplot(fig, filename='Data Train Scatter') #for offline usage (I'm not recommend this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### PNN Architecture\n",
    "As we see in the pnn architecture, \n",
    "![PNN Architecture](img/PNN.PNG)\n",
    "*Source : [Probabilistic Neural Netwoork Slide - Telkom University](https://www.google.com) <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer (or Pattern Layer)\n",
    "#### $g_i$ function \n",
    "\n",
    "$$\\huge g_i(X; \\sigma_i, W_i) = e^{-\\frac{1}{2} (\\frac{\\lVert X - W_i \\rVert}{\\sigma_i})^2} = e^{-\\frac{\\lVert  X - W_i  \\rVert ^2}{2\\sigma_i^2}} $$\n",
    "\n",
    "Where : <br>\n",
    "    $\\sigma_i$: the smoothing parameter for class $i$<br>\n",
    "    $W_i$ : The $i$-th dataTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g(x,sigma,w) :\n",
    "    y = x.sub(w, axis = 0) #data subtraction\n",
    "    y = la.norm(y.values)\n",
    "    return np.exp(- y / (2*sigma)**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in general we could write the function for patternLayer as below : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patternLayer(data,dataTrain, sigma_dict):\n",
    "    for i in dataTrain.index:\n",
    "        this_label = int(dataTrain.loc[i,'label'])\n",
    "        dataTrain.loc[i,'sigma'] = sigma_dict[this_label]\n",
    "        dataTrain.loc[i,'g'] = g(data, sigma_dict[this_label], dataTrain.loc[i,'att1':'att3'])\n",
    "    return dataTrain\n",
    "\n",
    "# def patternLayer(data,dataTrain, sigma_dict):\n",
    "#     for index, row in dataTrain.iterrows():\n",
    "#         this_label = row['label']\n",
    "#         row['sigma'] = sigma_dict[this_label]\n",
    "#         row['g']= g(data, sigma_dict[this_label], dataTrain.loc[i,'att1':'att3'])\n",
    "#     return dataTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example use of the pattern layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         att1      att2      att3  label  sigma         g\n",
      "0    1.026777 -3.279030 -0.883644      2    1.0  0.556049\n",
      "1    1.628673 -3.215970 -3.151889      2    1.0  1.000000\n",
      "2    0.923110  0.185698 -3.081089      2    1.0  0.419497\n",
      "3    1.210612  0.291462 -2.449537      2    1.0  0.406426\n",
      "4    2.544333  1.333560  2.078647      0    1.0  0.174100\n",
      "5   -0.505071  1.875051  3.537703      2    1.0  0.114376\n",
      "6    2.568030  1.993095  1.384366      0    1.0  0.175040\n",
      "7    1.145914 -3.007590 -1.695142      2    1.0  0.678966\n",
      "8   -2.642700  2.619429  1.057048      1    1.0  0.123462\n",
      "9    2.967126  0.940226  2.333582      0    1.0  0.173292\n",
      "10   1.241284  1.923449  1.571323      0    1.0  0.174171\n",
      "11  -0.440388  1.470366  3.067793      1    1.0  0.133396\n",
      "12   3.222067  2.810043  3.331670      0    1.0  0.105563\n",
      "13   2.378012  1.866489  2.025627      0    1.0  0.161468\n",
      "14   2.401919 -2.380048 -2.996957      2    1.0  0.750285\n",
      "15   2.649838 -3.573183 -1.532058      2    1.0  0.614486\n",
      "16   1.641112 -3.034926 -0.342372      2    1.0  0.494681\n",
      "17   3.312124  2.788081  2.179585      0    1.0  0.128603\n",
      "18   3.327532 -2.923872 -2.645522      2    1.0  0.638167\n",
      "19   2.956635  1.667679  1.862775      0    1.0  0.168443\n",
      "20  -0.953621  1.647064  2.118886      1    1.0  0.148740\n",
      "21  -1.530916  1.984400  1.753702      1    1.0  0.141702\n",
      "22   1.359711 -2.253716 -1.901888      2    1.0  0.670279\n",
      "23  -0.848654  0.817316  1.885271      1    1.0  0.177634\n",
      "24  -2.166917  1.811702  1.063153      1    1.0  0.150333\n",
      "25   2.156765 -1.391735 -0.260996      2    1.0  0.421168\n",
      "26  -2.595403  3.311696  2.503186      1    1.0  0.090396\n",
      "27  -1.880744  2.230180  2.110486      2    1.0  0.124096\n",
      "28  -2.422740  4.105229  3.208465      1    1.0  0.072252\n",
      "29  -1.239067  1.688796  2.330463      2    1.0  0.138922\n",
      "..        ...       ...       ...    ...    ...       ...\n",
      "120  1.875731 -3.084099 -1.580054      2    1.0  0.670892\n",
      "121  2.216932 -1.349832 -1.726862      2    1.0  0.545995\n",
      "122  2.647944 -2.463312 -1.398755      2    1.0  0.582301\n",
      "123 -0.552459  0.362882  3.034341      0    1.0  0.154421\n",
      "124  3.195660 -2.374259 -1.155505      2    1.0  0.512496\n",
      "125  3.372440 -3.382945 -1.788379      2    1.0  0.574093\n",
      "126  2.475420 -2.115729 -1.322991      2    1.0  0.563244\n",
      "127  4.164886  3.144925  2.870169      0    1.0  0.102306\n",
      "128  1.332856  1.886046  1.593446      0    1.0  0.174908\n",
      "129  1.725882 -2.975071 -1.933716      2    1.0  0.732428\n",
      "130  2.509963  0.271600  2.641720      1    1.0  0.181795\n",
      "131 -1.418637  1.986631  2.068231      1    1.0  0.136179\n",
      "132 -1.493641  2.126250  2.921803      1    1.0  0.114449\n",
      "133  3.446548 -2.207344 -0.078095      2    1.0  0.395460\n",
      "134 -1.845881  2.277819  2.461125      1    1.0  0.116823\n",
      "135  2.324591 -2.811614 -1.862856      2    1.0  0.683917\n",
      "136 -1.993192  2.417399  1.596729      1    1.0  0.128417\n",
      "137  2.494531  3.746201  3.065885      0    1.0  0.095978\n",
      "138 -3.687674  2.983932  2.046969      1    1.0  0.088889\n",
      "139 -0.881789  1.751633  2.783774      1    1.0  0.130777\n",
      "140  1.273901  3.194224  1.588173      2    1.0  0.136005\n",
      "141 -2.326482  2.879856  1.918376      1    1.0  0.109138\n",
      "142  0.000186  1.405577  0.451572      0    1.0  0.218581\n",
      "143  1.708787 -0.749965  0.254499      2    1.0  0.349407\n",
      "144  1.664034  2.577606  1.471001      0    1.0  0.156766\n",
      "145  2.428942 -2.031467 -0.035887      2    1.0  0.424406\n",
      "146  0.516294  2.205906  1.793810      0    1.0  0.156354\n",
      "147 -0.212367 -0.249616 -0.578701      2    1.0  0.338151\n",
      "148  1.332890  1.071313  1.394183      0    1.0  0.209308\n",
      "149  1.556651 -2.433995 -2.344159      2    1.0  0.754549\n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "z1 = dataTrain.loc[1,'att1':'att3']\n",
    "z2 = dataTrain.loc[:, 'att1':'label']\n",
    "\n",
    "sigmas = {0:1, 1:1, 2:1} #assuming that all classse have the sigma, 1\n",
    "z3 = patternLayer(z1,z2, sigmas)\n",
    "print(z3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summation Layer\n",
    "![PNN Architecture](img/PNN.PNG)\n",
    "*Source : [Probabilistic Neural Netwoork Slide - Telkom University](https://www.google.com) <br>\n",
    "\n",
    "\n",
    "The summation layer sums up all the g values of the data. But, the summation is applied only for the corresponding class. For example, $f_1$ is the summation for class 1. It sums up all the $g$s values in the data wich the class of the data is 1. <br>\n",
    "\n",
    "The $f$ function is written as follow : \n",
    "\n",
    "Univariate cases:\n",
    "$$ \\large f_i(g, \\sigma) = \\frac{1}{n\\sigma} \\sum_{k=1}^{n} g_k $$\n",
    "\n",
    "Multivariate cases:\n",
    "$$ \\large f_i(g,  \\sigma) = \n",
    "\\frac{1}{(2\\pi)^\\frac{p}{2}  \\sigma^p n} \\sum_{k=1}^{n}g_k $$\n",
    "\n",
    "So we could write the $f_i$ function in general like below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(g, sigma):\n",
    "    #g is in 'dataframe' format. \n",
    "#     return g.sum() / (len(g.index) * sigma)\n",
    "    return g.sum()['g'] / ((2*np.pi)**(3/2) * sigma**3 * len(g.index) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try this function by the following code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summation for class 0:  0.0102739804738\n",
      "Summation for class 1:  0.00929605611774\n",
      "Summation for class 2:  0.0314150702323\n"
     ]
    }
   ],
   "source": [
    "sigmas = {0:1, 1:1, 2:1} #assuming that all classse have the sigma, 1\n",
    "z1 = dataTrain.loc[1,'att1':'att3'] #data that we want to test\n",
    "z2 = dataTrain.loc[:, 'att1':'label'] #dataTrain\n",
    "\n",
    "plo = patternLayer(z1,z2, sigmas) #Pattern Layer Output\n",
    "plo_0 = plo.loc[plo['label'] == 0].reset_index(drop = True) #Patter Layer Output, Class 0\n",
    "plo_1 = plo.loc[plo['label'] == 1].reset_index(drop = True) #Patter Layer Output, Class 0\n",
    "plo_2 = plo.loc[plo['label'] == 2].reset_index(drop = True) #Patter Layer Output, Class 0\n",
    "\n",
    "print ('Summation for class 0: ',f(plo_0, sigmas[0]))\n",
    "print ('Summation for class 1: ',f(plo_1, sigmas[1]))\n",
    "print ('Summation for class 2: ',f(plo_2, sigmas[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is smoothing parameter ($\\sigma$)  ??\n",
    " $\\sigma$ is the smoothing parameter for each classes that responsible for the data's width of pdf curve. To find  $\\sigma$ , do the function \n",
    " $$sigma_i(\\textbf{data}) = \\large \\alpha  \\frac{\\sum_{k=1}^{n}  d_k}{n}   $$\n",
    "\n",
    "*Notes* : <br>\n",
    "    data : All the data in dataTrain that have the label of $i$. <br>\n",
    "    $\\alpha$ : a constant that you must observe <br>\n",
    "    $d_k$ : The nearest distance of the $k$-th data against another data. (You can simply use euclidian distance function)\n",
    "    \n",
    "In python you could write as follow :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_sigma(data, a):\n",
    "    idx = data.index\n",
    "    d = []\n",
    "    for i in idx:\n",
    "        currentData  = data.loc[i]\n",
    "#         print (currentData.shape)\n",
    "        neighborData = data.drop(data.index[i]) \n",
    "        neighborData = neighborData.sub(currentData,axis=1).values #Distance matrix\n",
    "        norms = [la.norm(j) for j in neighborData ]\n",
    "        d.append(min(norms)) #adding the minimum distance value\n",
    "    return (a * np.mean(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's try to find all the sigma for each classes using $\\alpha$ = 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma for class 0:  3.01123472667\n",
      "Sigma for class 1:  3.23698550025\n",
      "Sigma for class 2:  3.88967586818\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "print ('Sigma for class 0: ', f_sigma(class0, a))\n",
    "print ('Sigma for class 1: ', f_sigma(class1, a))\n",
    "print ('Sigma for class 2: ', f_sigma(class2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's continue to the summation layer\n",
    "\n",
    "## Summation Layer (cont'd)\n",
    "\n",
    "As we've seen that the summation layer only sum the corresponding classes of data. In other word, we must do $n$ times of $f_i$ in summation layer. And it will return $n$ values to the output layer.\n",
    "\n",
    "$$ Summation(data, sigma) = \\{A \\mid A_i = f_i(data_{class\\:i}, sigma_i)\\}$$\n",
    "\n",
    "So, we could generally write summation layer as : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summation(data, sigma):\n",
    "    classes = np.unique(data['label']) #find how many distinct classes \n",
    "    f_values = {}\n",
    "    for i in range (len(classes)):\n",
    "        class_i = data.loc[data['label'] == classes[i]].reset_index(drop = True)\n",
    "        sigma_i = sigma[classes[i]]\n",
    "        f_values.update({f(class_i, sigma_i):classes[i]})\n",
    "    return f_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.010273980473821663: 0, 0.0092960561177364096: 1, 0.031415070232304311: 2}\n"
     ]
    }
   ],
   "source": [
    "sigmas = {0:1, 1:1, 2:1} #assumption that all the sigma is 1\n",
    "z5 = dataTrain[1:2]\n",
    "\n",
    "for i in z5.index:\n",
    "    newData = z5.loc[i,'att1':'att3']\n",
    "    newDataTrain = dataTrain\n",
    "    plo = patternLayer(newData,newDataTrain, sigmas)\n",
    "    f_values = summation(plo, sigmas)\n",
    "    print (f_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Layer\n",
    "As we have the f_value , we can easily take the biggest value in f_value list bye the following code : <br>\n",
    "*Note : previous f_values is {0.010273980473821663: 0, 0.0092960561177364096: 1, 0.031415070232304311: 2}. <br>\n",
    "The biggest value is 0.031415070232304311, that should return 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputLayer(f_values):\n",
    "    maximum = -1\n",
    "    for key in f_values :\n",
    "        if maximum < key:\n",
    "            maximum = key\n",
    "    return f_values[maximum] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print (outputLayer(f_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done. \n",
    "Now, let's try to wrap it all as one classification function. :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, dataTrain, a):\n",
    "    \n",
    "    #Todo: Finding the sigmas \n",
    "    sigmas = {}\n",
    "    classlist = np.unique(dataTrain['label'])\n",
    "    for i in range (len(classlist)):\n",
    "        \n",
    "        class_i = dataTrain.loc[dataTrain['label'] == classlist[i]].reset_index(drop = True)\n",
    "        class_i = class_i.iloc[:,0:4]\n",
    "#         print (class_i.shape)\n",
    "#         print(f_sigma(class_i, a))\n",
    "        sigmas.update({classlist[i]:f_sigma(class_i, a)})\n",
    "    \n",
    "    \n",
    "    #Pattern Layer\n",
    "    plo = patternLayer(data,dataTrain, sigmas)\n",
    "    \n",
    "    #Summation Layer\n",
    "    f_values = summation(plo, sigmas)\n",
    "    #output Layer\n",
    "    newLabel = outputLayer(f_values)\n",
    "    return newLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in dataTest.index:\n",
    "    newData = dataTest.loc[i,'att1':'att3']\n",
    "    print (classify(newData,dataTrain,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  $\\sigma$ observation\n",
    "\n",
    "In order to observe the $\\sigma$, we must observe the value of $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try it yourself. Find a that give the optimum accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification\n",
    "\n",
    "If you found the best $\\alpha$ that gives the optimum accuracy (or minimum error), For example, the $\\alpha = 1$, so i try to classify the first 10 dataTrain and see how accurate it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data\n",
      "        att1      att2      att3  label\n",
      "1   1.628673 -3.215970 -3.151889      2\n",
      "2   0.923110  0.185698 -3.081089      2\n",
      "3   1.210612  0.291462 -2.449537      2\n",
      "4   2.544333  1.333560  2.078647      0\n",
      "5  -0.505071  1.875051  3.537703      2\n",
      "6   2.568030  1.993095  1.384366      0\n",
      "7   1.145914 -3.007590 -1.695142      2\n",
      "8  -2.642700  2.619429  1.057048      1\n",
      "9   2.967126  0.940226  2.333582      0\n",
      "10  1.241284  1.923449  1.571323      0\n",
      "\n",
      "After label deletion\n",
      "        att1      att2      att3\n",
      "1   1.628673 -3.215970 -3.151889\n",
      "2   0.923110  0.185698 -3.081089\n",
      "3   1.210612  0.291462 -2.449537\n",
      "4   2.544333  1.333560  2.078647\n",
      "5  -0.505071  1.875051  3.537703\n",
      "6   2.568030  1.993095  1.384366\n",
      "7   1.145914 -3.007590 -1.695142\n",
      "8  -2.642700  2.619429  1.057048\n",
      "9   2.967126  0.940226  2.333582\n",
      "10  1.241284  1.923449  1.571323\n",
      "\n",
      "After Classification\n",
      "        att1      att2      att3  label\n",
      "1   1.628673 -3.215970 -3.151889      2\n",
      "2   0.923110  0.185698 -3.081089      2\n",
      "3   1.210612  0.291462 -2.449537      2\n",
      "4   2.544333  1.333560  2.078647      0\n",
      "5  -0.505071  1.875051  3.537703      1\n",
      "6   2.568030  1.993095  1.384366      0\n",
      "7   1.145914 -3.007590 -1.695142      2\n",
      "8  -2.642700  2.619429  1.057048      1\n",
      "9   2.967126  0.940226  2.333582      0\n",
      "10  1.241284  1.923449  1.571323      0\n"
     ]
    }
   ],
   "source": [
    "a = 1 #assume that a = 1\n",
    "newDataTrain = dataTrain.iloc[:,0:4]\n",
    "outputData = dataTrain.iloc[1:11,0:4] #taking the first 10 data as output data\n",
    "print ('Original data')\n",
    "print (outputData)\n",
    "print()\n",
    "outputData = outputData.drop('label', axis=1, inplace=False) \n",
    "print ('After label deletion')\n",
    "print (outputData)\n",
    "print()\n",
    "\n",
    "# Classification\n",
    "for i in outputData.index:\n",
    "    newData = outputData.loc[i,'att1':'att3']\n",
    "    outputData.loc[i,'label'] = (classify (newData, newDataTrain,a))  \n",
    "outputData['label'] = outputData['label'].astype(np.int64) \n",
    "print ('After Classification')\n",
    "\n",
    "print (outputData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's not 100% accurate. You sould try and find another $\\alpha$. \n",
    "Thankyou :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
